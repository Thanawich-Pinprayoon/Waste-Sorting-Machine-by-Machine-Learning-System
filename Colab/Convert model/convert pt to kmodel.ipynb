{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"convert pt to kmodel.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1z2LGZeX4zHtlZLFCIFVtLN6yTqYF1SBE","authorship_tag":"ABX9TyM0PfkwrnZ/k9hs3fLXit9W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nWAd7jMeUefC","executionInfo":{"status":"ok","timestamp":1641707031889,"user_tz":-420,"elapsed":16396,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"74611469-286e-49e7-dd40-1ff1a4e369c3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","root_src_dir = \"/content/gdrive/MyDrive/CE_Project/model\"\n","root_dst_dir = \"/content/model\"\n","\n","for src_dir, dirs, files in os.walk(root_src_dir):\n","    dst_dir = src_dir.replace(root_src_dir, root_dst_dir, 1)\n","    if not os.path.exists(dst_dir):\n","        # print('making new dir.')\n","        os.makedirs(dst_dir)\n","    for file_ in files:\n","        src_file = os.path.join(src_dir, file_)\n","        dst_file = os.path.join(dst_dir, file_)\n","        if os.path.exists(dst_file):\n","            # print('file already exist.')\n","            try:\n","                # print('removing old file.')\n","                os.remove(dst_file)\n","            except PermissionError as exc:\n","                os.chmod(dst_file, stat.S_IWUSR)\n","                os.remove(dst_file)\n","        shutil.copy(src_file, dst_dir)"],"metadata":{"id":"orUyE_fsUnpg","executionInfo":{"status":"ok","timestamp":1641707330176,"user_tz":-420,"elapsed":281671,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["#Attempt 1 Fail output is Kmodel v5"],"metadata":{"id":"kNxN4GFwXiRh"}},{"cell_type":"code","source":["%cd /content/model/yolov5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2r1kOjxUuRy","executionInfo":{"status":"ok","timestamp":1640594742599,"user_tz":-420,"elapsed":11,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"4ec48b1e-c0c7-4325-e0a6-674fc40227d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model/yolov5\n"]}]},{"cell_type":"code","source":["# https://github.com/ultralytics/yolov5/issues/5707\n","%pip install --upgrade flatbuffers==1.12 # downgrade from v2 to v1.12"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXYSJdpQpn9G","executionInfo":{"status":"ok","timestamp":1640604590347,"user_tz":-420,"elapsed":4552,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"6b982ada-311f-4e23-f361-35499ffd7dde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flatbuffers==1.12\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Installing collected packages: flatbuffers\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","Successfully installed flatbuffers-1.12\n"]}]},{"cell_type":"code","source":["!python export.py --weights /content/model/yolov5/runs/train/exp3/weights/best.pt --img 224 --include onnx tflite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pnkTxJXVMTS","executionInfo":{"status":"ok","timestamp":1640606090120,"user_tz":-420,"elapsed":132243,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"00233827-e3a1-4e6a-8373-0a1cd9e1cb98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['/content/model/yolov5/runs/train/exp3/weights/best.pt'], imgsz=[224], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=14, verbose=False, workspace=4, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx', 'tflite']\n","YOLOv5 ðŸš€ v6.0-127-g554f782 torch 1.10.0+cu111 CPU\n","\n","Fusing layers... \n","Model Summary: 213 layers, 7066762 parameters, 0 gradients\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/model/yolov5/runs/train/exp3/weights/best.pt (57.2 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.10.2...\n","/content/model/yolov5/models/yolo.py:57: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  if self.onnx_dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n","WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n","WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n","/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_helper.py:716: UserWarning: allowzero=0 by default. In order to honor zero value in shape use allowzero=1\n","  warnings.warn(\"allowzero=0 by default. In order to honor zero value in shape use allowzero=1\")\n","WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n","WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n","WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n","WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success, saved as /content/model/yolov5/runs/train/exp3/weights/best.onnx (28.3 MB)\n","\u001b[34m\u001b[1mONNX:\u001b[0m run --dynamic ONNX model inference with: 'python detect.py --weights /content/model/yolov5/runs/train/exp3/weights/best.onnx'\n","\n","\u001b[34m\u001b[1mTensorFlow saved_model:\u001b[0m starting export with tensorflow 2.7.0...\n","\n","                 from  n    params  module                                  arguments                     \n","2021-12-27 11:52:49.221474: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     70122  models.yolo.Detect                      [21, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [224, 224]]\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(1, 224, 224, 3)]   0           []                               \n","                                                                                                  \n"," tf_conv (TFConv)               (1, 112, 112, 32)    3488        ['input_1[0][0]']                \n","                                                                                                  \n"," tf_conv_1 (TFConv)             (1, 56, 56, 64)      18496       ['tf_conv[0][0]']                \n","                                                                                                  \n"," tfc3 (TFC3)                    (1, 56, 56, 64)      18624       ['tf_conv_1[0][0]']              \n","                                                                                                  \n"," tf_conv_7 (TFConv)             (1, 28, 28, 128)     73856       ['tfc3[0][0]']                   \n","                                                                                                  \n"," tfc3_1 (TFC3)                  (1, 28, 28, 128)     115200      ['tf_conv_7[0][0]']              \n","                                                                                                  \n"," tf_conv_15 (TFConv)            (1, 14, 14, 256)     295168      ['tfc3_1[0][0]']                 \n","                                                                                                  \n"," tfc3_2 (TFC3)                  (1, 14, 14, 256)     623872      ['tf_conv_15[0][0]']             \n","                                                                                                  \n"," tf_conv_25 (TFConv)            (1, 7, 7, 512)       1180160     ['tfc3_2[0][0]']                 \n","                                                                                                  \n"," tfc3_3 (TFC3)                  (1, 7, 7, 512)       1181184     ['tf_conv_25[0][0]']             \n","                                                                                                  \n"," tfsppf (TFSPPF)                (1, 7, 7, 512)       656128      ['tfc3_3[0][0]']                 \n","                                                                                                  \n"," tf_conv_33 (TFConv)            (1, 7, 7, 256)       131328      ['tfsppf[0][0]']                 \n","                                                                                                  \n"," tf_upsample (TFUpsample)       (1, 14, 14, 256)     0           ['tf_conv_33[0][0]']             \n","                                                                                                  \n"," tf_concat (TFConcat)           (1, 14, 14, 512)     0           ['tf_upsample[0][0]',            \n","                                                                  'tfc3_2[0][0]']                 \n","                                                                                                  \n"," tfc3_4 (TFC3)                  (1, 14, 14, 256)     361216      ['tf_concat[0][0]']              \n","                                                                                                  \n"," tf_conv_39 (TFConv)            (1, 14, 14, 128)     32896       ['tfc3_4[0][0]']                 \n","                                                                                                  \n"," tf_upsample_1 (TFUpsample)     (1, 28, 28, 128)     0           ['tf_conv_39[0][0]']             \n","                                                                                                  \n"," tf_concat_1 (TFConcat)         (1, 28, 28, 256)     0           ['tf_upsample_1[0][0]',          \n","                                                                  'tfc3_1[0][0]']                 \n","                                                                                                  \n"," tfc3_5 (TFC3)                  (1, 28, 28, 128)     90496       ['tf_concat_1[0][0]']            \n","                                                                                                  \n"," tf_conv_45 (TFConv)            (1, 14, 14, 128)     147584      ['tfc3_5[0][0]']                 \n","                                                                                                  \n"," tf_concat_2 (TFConcat)         (1, 14, 14, 256)     0           ['tf_conv_45[0][0]',             \n","                                                                  'tf_conv_39[0][0]']             \n","                                                                                                  \n"," tfc3_6 (TFC3)                  (1, 14, 14, 256)     295680      ['tf_concat_2[0][0]']            \n","                                                                                                  \n"," tf_conv_51 (TFConv)            (1, 7, 7, 256)       590080      ['tfc3_6[0][0]']                 \n","                                                                                                  \n"," tf_concat_3 (TFConcat)         (1, 7, 7, 512)       0           ['tf_conv_51[0][0]',             \n","                                                                  'tf_conv_33[0][0]']             \n","                                                                                                  \n"," tfc3_7 (TFC3)                  (1, 7, 7, 512)       1181184     ['tf_concat_3[0][0]']            \n","                                                                                                  \n"," tf_detect (TFDetect)           ((1, 3087, 26),      70122       ['tfc3_5[0][0]',                 \n","                                 [(1, 3, 784, 26),                'tfc3_6[0][0]',                 \n","                                 (1, 3, 196, 26),                 'tfc3_7[0][0]']                 \n","                                 (1, 3, 49, 26)])                                                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,066,762\n","Trainable params: 0\n","Non-trainable params: 7,066,762\n","__________________________________________________________________________________________________\n","Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","2021-12-27 11:52:59.022108: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n","Assets written to: /content/model/yolov5/runs/train/exp3/weights/best_saved_model/assets\n","\u001b[34m\u001b[1mTensorFlow saved_model:\u001b[0m export success, saved as /content/model/yolov5/runs/train/exp3/weights/best_saved_model (240.3 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.7.0...\n","Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n","Assets written to: /tmp/tmp4_o9mvm1/assets\n","2021-12-27 11:54:43.853444: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n","2021-12-27 11:54:43.853516: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n","Estimated count of arithmetic ops: 2.149 G  ops, equivalently 1.074 G  MACs\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success, saved as /content/model/yolov5/runs/train/exp3/weights/best-fp32.tflite (28.3 MB)\n","\n","Export complete (124.57s)\n","Results saved to \u001b[1m/content/model/yolov5/runs/train/exp3/weights\u001b[0m\n","Visualize with https://netron.app\n"]}]},{"cell_type":"code","source":["!pip install onnx-simplifier\n","!pip install onnx\n","!pip install nncase"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSyazZDJwvr9","executionInfo":{"status":"ok","timestamp":1640594762067,"user_tz":-420,"elapsed":19477,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"5c3e57cb-6a05-4662-bddf-3a285cdfc119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx-simplifier in /usr/local/lib/python3.7/dist-packages (0.3.6)\n","Requirement already satisfied: onnxruntime>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (1.10.0)\n","Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (3.17.3)\n","Requirement already satisfied: onnxoptimizer>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (0.2.6)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (1.10.2)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.6.0->onnx-simplifier) (2.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.6.0->onnx-simplifier) (1.19.5)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.7.0->onnx-simplifier) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-simplifier) (3.10.0.2)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.10.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n","Requirement already satisfied: nncase in /usr/local/lib/python3.7/dist-packages (1.1.0.20211203)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nncase) (1.19.5)\n"]}]},{"cell_type":"code","source":["import os\n","import onnxsim\n","import onnx\n","import nncase\n","\n","def parse_model_input_output(model_file):\n","    onnx_model = onnx.load(model_file)\n","    input_all = [node.name for node in onnx_model.graph.input]\n","    input_initializer = [node.name for node in onnx_model.graph.initializer]\n","    input_names = list(set(input_all) - set(input_initializer))\n","    input_tensors = [node for node in onnx_model.graph.input if node.name in input_names]\n","\n","    # input\n","    inputs= []\n","    for _, e in enumerate(input_tensors):\n","        onnx_type = e.type.tensor_type\n","        input_dict = {}\n","        input_dict['name'] = e.name\n","        input_dict['dtype'] = onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[onnx_type.elem_type]\n","        input_dict['shape'] = [(i.dim_value if i.dim_value != 0 else d) for i, d in zip(\n","            onnx_type.shape.dim, [1, 3, 224, 224])]\n","        inputs.append(input_dict)\n","\n","\n","    return onnx_model, inputs\n","\n","def onnx_simplify(model_file):\n","    onnx_model, inputs = parse_model_input_output(model_file)\n","    onnx_model = onnx.shape_inference.infer_shapes(onnx_model)\n","    input_shapes = {}\n","    for input in inputs:\n","        input_shapes[input['name']] = input['shape']\n","\n","    onnx_model, check = onnxsim.simplify(onnx_model, input_shapes=input_shapes)\n","    assert check, \"Simplified ONNX model could not be validated\"\n","\n","    model_file = os.path.join(os.path.dirname(model_file), 'simplified.onnx')\n","    onnx.save_model(onnx_model, model_file)\n","    return model_file\n","\n","\n","def read_model_file(model_file):\n","    with open(model_file, 'rb') as f:\n","        model_content = f.read()\n","    return model_content\n","\n","\n","def main():\n","    model_file = '/content/model/yolov5/runs/train/exp3/weights/best.onnx'\n","    target = 'k210'\n","\n","    # onnx simplify\n","    model_file = onnx_simplify(model_file)\n","\n","    # compile_options\n","    compile_options = nncase.CompileOptions()\n","    compile_options.target = target\n","    compile_options.dump_ir = True\n","    compile_options.dump_asm = True\n","    compile_options.dump_dir = 'tmp'\n","\n","    # compiler\n","    compiler = nncase.Compiler(compile_options)\n","\n","    # import_options\n","    import_options = nncase.ImportOptions()\n","\n","    # import\n","    model_content = read_model_file(model_file)\n","    compiler.import_onnx(model_content, import_options)\n","\n","    # compile\n","    compiler.compile()\n","\n","    # kmodel\n","    kmodel = compiler.gencode_tobytes()\n","    with open('/content/model/yolov5/runs/train/exp3/weights/best_onnx.kmodel', 'wb') as f:\n","        f.write(kmodel)\n","\n","# if __name__ == '__main__':\n","main()"],"metadata":{"id":"u2vzPr1jwBbF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nncase\n","\n","def read_model_file(model_file):\n","    with open(model_file, 'rb') as f:\n","        model_content = f.read()\n","    return model_content\n","\n","def main():\n","    model='/content/model/yolov5/runs/train/exp3/weights/best-fp32.tflite'\n","    target = 'k210'\n","\n","    # compile_options\n","    compile_options = nncase.CompileOptions()\n","    compile_options.target = target\n","    compile_options.dump_ir = True\n","    compile_options.dump_asm = True\n","    compile_options.dump_dir = 'tmp'\n","\n","    # compiler\n","    compiler = nncase.Compiler(compile_options)\n","\n","    # import_options\n","    import_options = nncase.ImportOptions()\n","\n","    # import\n","    model_content = read_model_file(model)\n","    compiler.import_tflite(model_content, import_options)\n","\n","    # compile\n","    compiler.compile()\n","\n","    # kmodel\n","    kmodel = compiler.gencode_tobytes()\n","    with open('/content/model/yolov5/runs/train/exp3/weights/best_tflite.kmodel', 'wb') as f:\n","        f.write(kmodel)\n","\n","# if __name__ == '__main__':\n","main()"],"metadata":{"id":"yJGDv5L8V9FU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nncase\n","\n","def read_model_file(model_file):\n","    with open(model_file, 'rb') as f:\n","        model_content = f.read()\n","    return model_content\n","\n","def main():\n","    model='/content/model/yolov5/runs/train/exp3/weights/best-fp32.tflite'\n","    target = 'k210'\n","\n","    # compile_options\n","    compile_options = nncase.CompileOptions()\n","    compile_options.target = target\n","    compile_options.input_type = 'float32'  # or 'uint8' 'int8' 'float32'\n","    compile_options.preprocess = True # if False, the args below will unworked\n","    compile_options.swapRB = True\n","    compile_options.input_shape = [1,224,224,3] # keep layout same as input layout\n","    compile_options.input_layout = 'NHWC'\n","    compile_options.output_layout = 'NHWC'\n","    compile_options.mean = [0,0,0]\n","    compile_options.std = [1,1,1]\n","    compile_options.input_range = [0,1]\n","    compile_options.letterbox_value = 114. # pad what you want\n","    compile_options.dump_ir = True\n","    compile_options.dump_asm = True\n","    compile_options.dump_dir = 'tmp'\n","\n","    # compiler\n","    compiler = nncase.Compiler(compile_options)\n","\n","    # import_options\n","    import_options = nncase.ImportOptions()\n","\n","    # import\n","    model_content = read_model_file(model)\n","    compiler.import_tflite(model_content, import_options)\n","\n","    # compile\n","    compiler.compile()\n","\n","    # kmodel\n","    kmodel = compiler.gencode_tobytes()\n","    with open('/content/model/yolov5/runs/train/exp3/weights/best_tflite_preprocess.kmodel', 'wb') as f:\n","        f.write(kmodel)\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"5JgAOE3MD98_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save to drive\n","root_src_dir = \"/content/model\"\n","root_dst_dir = \"/content/gdrive/MyDrive/CE_Project/model\"\n","\n","for src_dir, dirs, files in os.walk(root_src_dir):\n","    dst_dir = src_dir.replace(root_src_dir, root_dst_dir, 1)\n","    if not os.path.exists(dst_dir):\n","        # print('making new dir.')\n","        os.makedirs(dst_dir)\n","    for file_ in files:\n","        src_file = os.path.join(src_dir, file_)\n","        dst_file = os.path.join(dst_dir, file_)\n","        if os.path.exists(dst_file):\n","            # print('file already exist.')\n","            try:\n","                # print('removing old file.')\n","                os.remove(dst_file)\n","            except PermissionError as exc:\n","                os.chmod(dst_file, stat.S_IWUSR)\n","                os.remove(dst_file)\n","        shutil.copy(src_file, dst_dir)"],"metadata":{"id":"seunK6oLYrE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ydBf-sLzYtLR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Attepmt 2 use NCC v0.2.0 beta4"],"metadata":{"id":"dyTPpCDmXblP"}},{"cell_type":"code","source":["%cd /content/model/ncc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Vj9_uu9YJy4","executionInfo":{"status":"ok","timestamp":1641707440939,"user_tz":-420,"elapsed":316,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"62fe5513-bd24-48e8-bede-6e1da6684d71"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model/ncc\n"]}]},{"cell_type":"code","source":["!sudo pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iamBMqhQZNrM","executionInfo":{"status":"ok","timestamp":1641707725975,"user_tz":-420,"elapsed":346,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"cdff2af8-1a87-4775-e00b-f21076052444"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model/ncc\n"]}]},{"cell_type":"code","source":["!./ncc best.onnx best-onnx.kmodel -i onnx -o kmodel -t k210 --dataset images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJQ9o-9kYVTj","executionInfo":{"status":"ok","timestamp":1641708705461,"user_tz":-420,"elapsed":359,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"3652ff17-3847-408c-b7ab-9f107936a553"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: ./ncc: Permission denied\n"]}]},{"cell_type":"markdown","source":["#Attempt 3 kendryte-standalone-sdk"],"metadata":{"id":"QYt5ugpla70t"}},{"cell_type":"markdown","source":["https://github.com/kendryte/kendryte-standalone-sdk"],"metadata":{"id":"bwKhxt8td4mt"}},{"cell_type":"code","source":["%cd /content/model/SDK"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTl8dCN9eDG7","executionInfo":{"status":"ok","timestamp":1641708831735,"user_tz":-420,"elapsed":347,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"4dfb1a21-9397-452f-a81c-ef3d79dd5c54"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model/SDK\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/kendryte/kendryte-standalone-sdk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMT_f_bDd3Sm","executionInfo":{"status":"ok","timestamp":1641708848273,"user_tz":-420,"elapsed":2129,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"65d68ff2-8920-4d93-ef12-bc38fc594ccf"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'kendryte-standalone-sdk'...\n","remote: Enumerating objects: 3937, done.\u001b[K\n","remote: Counting objects: 100% (337/337), done.\u001b[K\n","remote: Compressing objects: 100% (147/147), done.\u001b[K\n","remote: Total 3937 (delta 186), reused 297 (delta 161), pack-reused 3600\u001b[K\n","Receiving objects: 100% (3937/3937), 10.79 MiB | 18.95 MiB/s, done.\n","Resolving deltas: 100% (2713/2713), done.\n"]}]},{"cell_type":"code","source":["%cd /content/model/SDK/kendryte-standalone-sdk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qjTe3VEzeR1E","executionInfo":{"status":"ok","timestamp":1641708874840,"user_tz":-420,"elapsed":318,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"5a8fedde-7dbb-4a78-9f72-f27fc4c7cd1d"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model/SDK/kendryte-standalone-sdk\n"]}]},{"cell_type":"code","source":["%cd src"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMfVtEv8eXtB","executionInfo":{"status":"ok","timestamp":1641708939224,"user_tz":-420,"elapsed":347,"user":{"displayName":"THANAWICH PINPRAYOON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_r-yP9P0YVjkbHzfwyTkP1OuK6XrSUA7N5wRykw=s64","userId":"17639497040282183877"}},"outputId":"e6a4faf0-43fb-42c3-d9a4-b47d594c475a"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model/SDK/kendryte-standalone-sdk/src\n"]}]},{"cell_type":"code","source":["cd"],"metadata":{"id":"3xaBFL1VenKn"},"execution_count":null,"outputs":[]}]}